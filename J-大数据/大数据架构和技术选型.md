# 大数据架构

## 源数据层

- sdk日志埋点；
- 日志文件：爬虫日志、业务日志；
- 关系型数据库：MySQL等

## 数据采集层

- 离线：flume、Sqoop、Nifi；
- 实时：filebeat、nginx+lua；
- 补充：当数据量达到5亿左右的时候，filebeat+logstash采集数据到hdfs，数据会出现丢失的情况，所以此种方案不适合用于大数据存储到HDFS。

## 数据存储层

- HDFS用于存储离线大数据量；
- kudu用于存储MySQL关系数据库更新变化的数据；
- ES存储一些log日志；
- kafka存储filebeat或flume采集的日志；

## 数据分析层

- ES，分析一些log；
- hive适用于分析一些离线大数据（基于磁盘IO分析）
- impala、presto适用于分析一些**准实时**日志（要求快速出数据，基于内存分析）
- spark core + spark sql适用于分析一些离线数据，自定义解析规则；
- spark streaming 适用于分析一些实时（不完全实时）数据；
- flink、jstorm进行分析**完全实时**的数据；

## 数据调度层

- airflow：适用于大集群，阿里的调度系统就是根据airflow二次开发，配置复杂，Python脚本实现；
- azkaban：CPU和内存要求不搞，主从配置支持的不算太好，适用于小集群，以job的文件实现，配置简单；
- oozie：通常hue集成，单独使用oozie的情况下，配置极其复杂，不建议使用，所有的任务是以mr的形式进行的，可支持复杂的依赖调度；
- jobX：CPU使用高，bug还没修复，所以造成agent的CPU维持在1个左右，配置简单，只支持依赖调度，不支持并行调度；
- corntab：一般用于每分钟调度1次的任务，不支持依赖调度、并行调度（配置复杂，通过脚本自定义控制），没有可视化界面，不能准确的判断任务是否成功或者失败；
- NiFi：不止支持数据调度，还支持数据同步，功能很强。
- 自定义，公司自己开发；

## 数据同步层

- sqoop用的是1.x系列版本；
- datax
- kettle
- NiFi

## 数据OLAP存储层

MySQL、ES、TiDB、Redis、Hbase、Clickhouse；

补充：有时间的话研究一下TiDB和Clickhouse。

## 数据展示层

PowerBI、帆软等BI可视化工具、前端定制开发。

# 技术选型

## 实时分析

可以使用lua或filebeat将nginx数据采集到kafka，数据经过spark streaming或jstorm解析后，尽可能的存入一些高吞吐量的数据库（非关系型），但有时必须要存入一些关系型数据库，比如MySQL，但是spark streaming发现仅仅通过一个map操作，每个执行的batch的时间，就超过我们所设置的batch时间，这时我们需要一个措施，增加一个缓冲层，不直接些MySQL或redis，先写入kafka，然后通过kafka推送到独立的写入服务，这样会发现实时处理服务的时间明显降低。

## 离线分析

- 采集这块用flume的tailf形式，或使用sqoop和nifi；

- 数据分析使用Hive、SparkSql，
- 数据存储使用HDFS；
- 最终将数据导出到MySQL等常用的关系型数据库中。

## 组件版本号

- Cloudera Manager：6.2.1；
- CDH：6.2.1；
- Hadoop：3.0.0-CDH6.2.1；
- HBase：2.1.0-CDH6.2.1；
- Hive：2.1.1--CDH6.2.1；
- Kafka：2.1.0--CDH6.2.1；
- Kudu：1.9.0-CDH6.2.1；
- Oozie：5.1.0-CDH6.2.1；
- Spark：2.4.0-CDH6.2.1；
- Sqoop：1.4.7-CDH6.2.1；
- ZooKeeper：3.4.5-CDH6.2.1；

