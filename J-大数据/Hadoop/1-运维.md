# 安装

## 创建文件夹

```shell
# 在/opt目录下创建module、software文件夹
sudo mkdir module software
# 修改module、software文件夹的所有者
sudo chown -R idc:idc module/ software/
```

## 安装JDK

### 下载并解压

```shell
# 解压到 module 目录下
tar -zxvf jdk-8u251-linux-x64.tar.gz -C /opt/module/
```

### 配置环境变量

```shell
sudo vim /etc/profile

# shift + G 跳到最后一行，增加如下内容：
# JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_251
export PATH=$PATH:$JAVA_HOME/bin

# source 刷新配置
source /etc/profile
```

## 安装Hadoop

### 编译

为什么安装前需要编译？

因为Apache给出的安装包没有提供带C程序访问的接口，在使用本地库（本地库可以压缩及支持C程序等）时会出问题。

#### 编译前环境准备

##### 准备Linux环境

一台Linux，内存4G以上，能联网，使用root权限。

##### 安装jdk

```shell
# 解压
cd /opt/software
tar -zxf jdk-8u144-linux-x64.tar.gz -C /opt/module/
# /etc/profile末尾添加环境变量 
## JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_144
export PATH=$PATH:$JAVA_HOME/bin
# 让环境变量生效
source /etc/profile
```

##### 安装maven

```shell
# 解压
cd /opt/software
tar -zxf apache-maven-3.0.5-bin.tar.gz -C /opt/module
# /etc/profile末尾添加环境变量
## MAVEN_HOME 
export MAVEN_HOME=/opt/module/apache-maven-3.0.5 
export PATH=$PATH:$MAVEN_HOME/bin
# 生效
source /etc/profile
# 配置镜像仓库
cd $MAVEN_HOME/conf/
vim settings.xml
```

```xml
<mirror>
	<id>aliyunmaven</id>
	<mirrorOf>*</mirrorOf>
	<name>阿里云公共仓库</name>
	<url>https://maven.aliyun.com/repository/public</url>
</mirror>
```

##### 安装 c++相关

为后面编译 protobuf 做准备

```shell
yum install glibc-headers
yum install gcc-c++
yum install make
yum install cmake
```

##### 安装protobuf

```shell
# 解压
cd /opt/software
tar -zxf protobuf-2.5.0.tar.gz -C /opt/module/
# 编译
cd /opt/module/protobuf-2.5.0/
./configure
make
make check
make install
ldconfig
# /etc/profile末尾添加环境变量
## LD_LIBRARY_PATH 
export LD_LIBRARY_PATH=/opt/module/protobuf-2.5.0 
export PATH=$PATH:$LD_LIBRARY_PATH
# 生效
source /etc/profile
# 验证
$ protoc --version
```

##### 安装其他依赖库

```shell
# openssl 库
yum install openssl-devel
# ncurses-devel 库
yum install ncurses-devel
```

#### 开始编译

```shell
# 下载hadoop源码包，并解压
tar xzf hadoop-2.7.2-src.tar.gz -C /opt/source/
# 进入源码主目录
cd /opt/source/hadoop-2.7.2-src
# 编译(估计需要30分钟)
mvn package -Pdist,nativeN -DskipTests -Dtar
# 查看编译结果
cd /opt/source/hadoop-2.7.2-src/hadoop-dist/target
```

#### 常见问题及解决方案

- mvn install 时候 JVM 内存溢出：在配置文件和执行文件均可调整 `MAVEN_OPT` 的heap大小（ http://outofmemory.cn/code-snippet/12652/maven-outofmemoryerror-method） 

- 编译期间maven报错。可能是网络导致依赖库下载不完整，多执行几次编译命令 （一次通过比较难）

- 报 ant、protobuf 错误、插件下载未完整、插件版本，最开始链接有较多特殊情况，2.7.0 版本问题汇总帖http://www.tuicool.com/articles/IBn63qf

### 安装

```shell
# 解压编译后的jar包到 /opt/module目录
tar xzf hadoop-2.7.2.tar.gz -C /opt/module
# 配置环境变量
vim /etc/profile
## HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-2.7.2
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
# 生效
source /etc/profile
```

# 单机

## 安装

根据上面的步骤。

## 运行

```sh
# 官方示例：
# https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html

# 创建一个目录，存放输入文件
$ cd $HADOOP_HOME
$ mkdir input
$ cp etc/hadoop/*.xml input

# 执行share目录下的MapReduce示例程序
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'
$ cat output/*
```

# 集群搭建

## 规划

|      | hadoop101                  | hadoop102                            | hadoop103                           |
| ---- | -------------------------- | ------------------------------------ | ----------------------------------- |
| HDFS | ==NameNode== <br/>DataNode | DataNode                             | ==SecondaryNameNode== <br/>DataNode |
| YARN | NodeManager                | ==ResourceManager==<br/> NodeManager | NodeManager                         |

## 环境准备

1. 静态IP
2. 关闭防火墙和SELinux
3. 修改主机名
4. 创建非root用户
5. 免密登录
6. Hosts映射

## 部署

### 安装

参考上面的安装

### 配置

#### 配置核心

core-site.xml

```xml
<!-- 默认文件系统名称 -->
<property>
		<name>fs.defaultFS</name>
    <value>hdfs://hadoop101:9000</value>
</property>
<!-- 运行时产生文件的存储路径 -->
<property>
		<name>hadoop.tmp.dir</name>
		<value>/opt/module/hadoop-2.7.2/data/tmp</value>
</property>
<!--缓冲区大小，实际工作中根据服务器性能动态调整-->
<property>
  <name>io.file.buffer.size</name>
  <value>4096</value>
</property>
```

#### 配置各模块

##### HDFS

hadoop-env.sh

```sh
export JAVA_HOME=/opt/module/jdk1.8.0_144
```

hdfs-site.xml

```xml
<!--副本数-->
<property>
		<name>dfs.replication</name>
		<value>3</value>
</property>
<!-- 指定 Hadoop 辅助（secondary）名称节点主机配置 -->
<property>
      <name>dfs.namenode.secondary.http-address</name>
      <value>hadoop103:50090</value>
</property>
```

##### YARN

yarn-env.sh

```sh
export JAVA_HOME=/opt/module/jdk1.8.0_144
```

yarn-site.xml

```xml
<!-- Reducer获取数据的方式 -->
<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
</property>
<!-- 指定YARN的 ResourceManager 的地址 -->
<property>
		<name>yarn.resourcemanager.hostname</name>
		<value>hadoop102</value>
</property>
<!-- 日志聚集功能使能 --> 
<property>
  <name>yarn.log-aggregation-enable</name> 
  <value>true</value> 
</property>
<!-- 日志保留时间设置 7 天 --> 
<property> 
  <name>yarn.log-aggregation.retain-seconds</name> 
  <value>604800</value> 
</property>
```

##### MapReduce

mapred-env.sh

```wiki
export JAVA_HOME=/opt/module/jdk1.8.0_144
```

mapred-site.xml（复制mapred-site.xml.template模板，修改名称）

```xml
<!-- 指定MR运行在Yarn上 -->
<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
</property>
```

#### 配置Slaves

```sh
vim /$HADOOP_HOME/etc/hadoop/slaves
# 添加如下节点主机名（注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。）
hadoop101
hadoop102
hadoop103

# 同步所有节点配置文件
xsync /$HADOOP_HOME/etc/hadoop/
```

### 同步

#### 安装和配置

把同步脚本放到`/home/<username>/bin/`目录下，并修改权限`chmod 777 xsync`，注意这里必须是777才能全局使用，如果还是不能全局使用，则放到 `/usr/local/bin/`目录下试试。

```sh
# 同步安装：JDK和Hadoop
xsync /opt/software/
xsync /opt/module/
# 同步配置
xsync /etc/profile
xsync /etc/hosts
```

```sh
#!/bin/bash 
#1 输入参数个数 
pcount=$# 
# 如果没有参数，直接退出
if((pcount==0)); 
then 
	echo no args; 
exit; 
fi

#2 第一个参数，即要同步的文件
p1=$1
# 获取文件名文件名称（去掉绝对路径）
fname=`basename $p1` 
echo fname=$fname

#3 上级目录的绝对路径
pdir=`cd -P $(dirname $p1); pwd` 
echo pdir=$pdir

#4 当前用户名
user=`whoami`

#5 循环 
for((host=101; host<103; host++)); 
do 
	echo ------------------- hadoop$host -------------
	rsync -rvl $pdir/$fname $user@hadoop$host:$pdir 
done
```

#### 集群时间

查看【运维】--->【Linux】--->【网络管理】

### 启动

#### 逐个启动

```sh
hadoop namenode -format
hadoop-daemon.sh start namenode
hadoop-daemon.sh start datanode
```

#### 集群启动

```sh
cd $HADOOP_HOME
# 1. 如果已经启动，需要先停掉
# 2. 如果集群是第一次启动，需要格式化NameNode（注意：格式化之前，一定要先停止所有namenode和datanode进程，然后再删除data和log数据）
rm -rf data/ logs/
hadoop namenode -format

# 启动 HDFS。在 NameNode 节点执行
sbin/start-dfs.sh
# 启动 YARN。在 ResouceManager 执行。
sbin/start-yarn.sh
# 启动历史服务（可以不开启）
sbin/mr-jobhistory-daemon.sh start historyserver
```

### 查看

#### 日志

```sh
cd $HADOOP_HOME/logs
```

#### 后台

```wiki
# HDFS
## 查看 NameNode
http://hadoop101:50070/
## 查看 SecondaryNameNode
http://hadoop103:50090/

## web 端查看 HDFS 文件系统。如果不能查看，看如下帖子处理：
http://www.cnblogs.com/zlslch/p/6604189.html

# YARN
## ResourceManager
http://hadoop102:8088/

# 查看 JobHistory
http://hadoop101:19888/jobhistory
```

### 测试

```sh
cd $HADOOP_HOME

# 创建目录
hdfs dfs -mkdir -p /user/idc/input

# 上传文件
hdfs dfs -put etc/hadoop/*.xml input
hdfs dfs -put /opt/software/hadoop-2.7.2.tar.gz /user/idc/input

## 上传后的文件存放在【data目录（可在配置中更改）】
cd /$HADOOP_HOME/data/tmp/dfs/data/current/BP-1426919963-10.0.1.41-1597064400885/current/finalized/subdir0/subdir0

## 从HDFS后台 http://hadoop101:50070/ 可以看到文件被分成2个block，可以手动拼接
cat blk_1073741826 >> tmp.txt
cat blk_1073741827 >> tmp.txt
tar -zxvf tmp.txt

# 运行 MapReduce 示例
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'

# 检查输出
## 下载并查看
hdfs dfs -get output output
cat output/*
## 直接在HDFS上查看
hdfs dfs -cat output/*

## 删除
hdfs dfs -rm -R /user/idc/input
hdfs dfs -rm -R /user/idc/output
```

### 基准测试

实际生产环境中，环境搭建完成之后，第一件事是压测，测试集群读写速度及网络带宽。

```sh
# 写入测试
## 向HDFS写入数据，10个文件，每个10MB，文件存放在/benchmarks/TestDFSIO
cd /$HADOOP_HOME/share/hadoop/mapreduce
hadoop jar hadoop-mapreduce-client-jobclient-2.7.2.jar TestDFSIO -write -nrFiles 10 -fileSize 10MB
## 查看
### 到后台查看
/benchmarks/TestDFSIO
### 命令行查看
cat TestDFSIO_results.log

## 读取测试
hadoop jar hadoop-mapreduce-client-jobclient-2.7.2.jar TestDFSIO -read -nrFiles 10 -fileSize 10MB

## 清楚测试数据
hadoop jar hadoop-mapreduce-client-jobclient-2.7.2.jar TestDFSIO -clean
```

### 停止

```sh
# HDFS。 在 NameNode 节点执行
sbin/stop-dfs.sh

# YARN。在 ResourceManager 节点执行
## 停止YARN
sbin/stop-yarn.sh
## 停止历史服务
sbin/mr-jobhistory-daemon.sh stop historyserver
```

